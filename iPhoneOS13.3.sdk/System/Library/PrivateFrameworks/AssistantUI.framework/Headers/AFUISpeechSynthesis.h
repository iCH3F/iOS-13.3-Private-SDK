//
//     Generated by class-dump 3.5 (64 bit) (Debug version compiled Mar 22 2020 01:47:48).
//
//  Copyright (C) 1997-2019 Steve Nygard.
//

#import <objc/NSObject.h>

#import <AssistantUI/AFQueueDelegate-Protocol.h>
#import <AssistantUI/AFUISpeechSynthesis-Protocol.h>
#import <AssistantUI/AFUISpeechSynthesisElementDelegate-Protocol.h>
#import <AssistantUI/VSSpeechSynthesizerDelegate-Protocol.h>

@class AFQueue, AFSiriClientStateManager, AFVoiceInfo, NSMutableArray, NSMutableDictionary, VSSpeechSynthesizer;
@protocol AFUISpeechSynthesisDelegate, AFUISpeechSynthesisLocalDelegate, OS_dispatch_group, OS_dispatch_queue;

@interface AFUISpeechSynthesis : NSObject <AFQueueDelegate, AFUISpeechSynthesisElementDelegate, VSSpeechSynthesizerDelegate, AFUISpeechSynthesis>
{
    VSSpeechSynthesizer *_synthesizer;
    AFSiriClientStateManager *_siriClientStateManager;
    unsigned int _sessionID;
    AFVoiceInfo *_outputVoice;
    NSMutableDictionary *_availableVoicesForLanguage;
    NSObject<OS_dispatch_queue> *_processingElementsQueue;
    NSObject<OS_dispatch_queue> *_pendingElementsQueue;
    NSObject<OS_dispatch_group> *_pendingElementsGroup;
    id <AFUISpeechSynthesisDelegate> _delegate;
    id <AFUISpeechSynthesisLocalDelegate> _localDelegate;
    AFQueue *_elementQueue;
    NSMutableArray *_activeElements;
    NSMutableDictionary *_delayedElements;
}

@property(readonly, nonatomic, getter=_delayedElements) NSMutableDictionary *delayedElements; // @synthesize delayedElements=_delayedElements;
@property(readonly, nonatomic, getter=_activeElements) NSMutableArray *activeElements; // @synthesize activeElements=_activeElements;
@property(readonly, nonatomic, getter=_elementQueue) AFQueue *elementQueue; // @synthesize elementQueue=_elementQueue;
@property(retain, nonatomic) id <AFUISpeechSynthesisDelegate> delegate; // @synthesize delegate=_delegate;
@property(nonatomic) __weak id <AFUISpeechSynthesisLocalDelegate> localDelegate; // @synthesize localDelegate=_localDelegate;
// - (void).cxx_destruct;
- (void)_setSiriClientStateManager:(id)arg1;
- (void)_setSynthesizer:(id)arg1;
- (void)_processProvisionalElements;
- (id)_filterVoices:(id)arg1 gender:(id)arg2;
- (long long)_genderForString:(id)arg1;
- (void)_findVoiceForLanguage:(id)arg1 gender:(id)arg2 completion:(id /* CDUnknownBlockType */)arg3;
- (id)_activeElementWithSpeechRequest:(id)arg1;
- (id)_activeElementWithPresynthesizedAudioRequest:(id)arg1;
- (void)_processElementQueue;
- (void)_handleText:(id)arg1 completion:(id /* CDUnknownBlockType */)arg2;
- (void)_handleAudioData:(id)arg1 completion:(id /* CDUnknownBlockType */)arg2;
- (void)processDelayedItem:(id)arg1;
- (void)enqueueText:(id)arg1 identifier:(id)arg2 completion:(id /* CDUnknownBlockType */)arg3;
- (void)_enqueueText:(id)arg1 audioData:(id)arg2 identifier:(id)arg3 language:(id)arg4 gender:(id)arg5 isPhonetic:(BOOL)arg6 provisionally:(BOOL)arg7 eligibleAfterDuration:(double)arg8 delayed:(BOOL)arg9 canUseServerTTS:(BOOL)arg10 preparationIdentifier:(id)arg11 shouldCache:(BOOL)arg12 synthesizesWhileRecording:(BOOL)arg13 completion:(id /* CDUnknownBlockType */)arg14 animationIdentifier:(id)arg15 analyticsContext:(id)arg16 speakableContextInfo:(id)arg17;
- (void)enqueuePhaticWithCompletion:(id /* CDUnknownBlockType */)arg1;
- (void)enqueueAudioData:(id)arg1 identifier:(id)arg2 provisionally:(BOOL)arg3 eligibleAfterDuration:(double)arg4 completion:(id /* CDUnknownBlockType */)arg5;
- (void)enqueueText:(id)arg1 identifier:(id)arg2 language:(id)arg3 gender:(id)arg4 isPhonetic:(BOOL)arg5 provisionally:(BOOL)arg6 eligibleAfterDuration:(double)arg7 delayed:(BOOL)arg8 canUseServerTTS:(BOOL)arg9 preparationIdentifier:(id)arg10 completion:(id /* CDUnknownBlockType */)arg11 animationIdentifier:(id)arg12 analyticsContext:(id)arg13 speakableContextInfo:(id)arg14;
- (void)setAudioSessionID:(unsigned int)arg1;
- (void)setOutputVoice:(id)arg1;
- (void)speechSynthesizer:(id)arg1 didFinishSpeakingRequest:(id)arg2 withInstrumentMetrics:(id)arg3;
- (void)speechSynthesizer:(id)arg1 didFinishSpeakingRequest:(id)arg2 successfully:(BOOL)arg3 phonemesSpoken:(id)arg4 withError:(id)arg5;
- (void)speechSynthesizer:(id)arg1 didStartSpeakingRequest:(id)arg2;
- (void)speechSynthesizer:(id)arg1 didFinishPresynthesizedAudioRequest:(id)arg2 withInstrumentMetrics:(id)arg3 error:(id)arg4;
- (void)speechSynthesizer:(id)arg1 didStopPresynthesizedAudioRequest:(id)arg2 atEnd:(BOOL)arg3 error:(id)arg4;
- (void)speechSynthesizer:(id)arg1 didStartPresynthesizedAudioRequest:(id)arg2;
- (void)speechSynthesisElementSynthesisEligibilityDidChange:(id)arg1;
- (void)queue:(id)arg1 didEnqueueObjects:(id)arg2;
- (void)invalidate;
- (void)invalidateOnMainThread;
- (void)_cancelByCancellingActiveElementsOnly:(BOOL)arg1;
- (void)skipCurrentSynthesis;
- (void)cancel;
- (BOOL)_isSynthesisQueueEmpty;
- (void)isSynthesisQueueEmpty:(id /* CDUnknownBlockType */)arg1;
- (BOOL)isSpeaking;
- (void)prewarmIfNeeded;
- (id)_siriClientStateManager;
- (id)_synthesizer;
- (id)init;

@end

